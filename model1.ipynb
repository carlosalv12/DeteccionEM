{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6103a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\carlo\\anaconda3\\lib\\site-packages (4.52.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: datasets in c:\\users\\carlo\\anaconda3\\lib\\site-packages (3.6.0)\n",
      "Requirement already satisfied: torch in c:\\users\\carlo\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: torchvision in c:\\users\\carlo\\anaconda3\\lib\\site-packages (0.22.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from transformers) (0.31.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\carlo\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
      "   ---------------------------------------- 0.0/10.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.6/10.5 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.4/10.5 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.8/10.5 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.9/10.5 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.4/10.5 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.4/10.5 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.0/10.5 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.0/10.5 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.5/10.5 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "   ---------------------------------------- 0.0/216.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/216.1 MB 8.3 MB/s eta 0:00:26\n",
      "    --------------------------------------- 3.4/216.1 MB 8.4 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 5.5/216.1 MB 9.1 MB/s eta 0:00:24\n",
      "   - -------------------------------------- 7.6/216.1 MB 9.4 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 9.7/216.1 MB 9.4 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 11.8/216.1 MB 9.3 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 13.6/216.1 MB 9.4 MB/s eta 0:00:22\n",
      "   -- ------------------------------------- 15.7/216.1 MB 9.4 MB/s eta 0:00:22\n",
      "   --- ------------------------------------ 18.4/216.1 MB 9.6 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 20.4/216.1 MB 9.7 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 22.5/216.1 MB 9.7 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 24.9/216.1 MB 9.8 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 26.7/216.1 MB 9.7 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 29.1/216.1 MB 9.8 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 31.2/216.1 MB 9.8 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 33.3/216.1 MB 9.9 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 35.4/216.1 MB 9.8 MB/s eta 0:00:19\n",
      "   ------ --------------------------------- 37.2/216.1 MB 9.8 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 39.3/216.1 MB 9.7 MB/s eta 0:00:19\n",
      "   ------- -------------------------------- 41.4/216.1 MB 9.7 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 43.0/216.1 MB 9.6 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 44.6/216.1 MB 9.5 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 45.6/216.1 MB 9.3 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 47.2/216.1 MB 9.2 MB/s eta 0:00:19\n",
      "   -------- ------------------------------- 48.2/216.1 MB 9.1 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 49.3/216.1 MB 8.9 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 50.3/216.1 MB 8.8 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 51.4/216.1 MB 8.6 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 52.2/216.1 MB 8.5 MB/s eta 0:00:20\n",
      "   --------- ------------------------------ 53.2/216.1 MB 8.3 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 54.3/216.1 MB 8.2 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 55.3/216.1 MB 8.1 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 56.4/216.1 MB 8.0 MB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 57.4/216.1 MB 7.9 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 59.0/216.1 MB 7.9 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 60.8/216.1 MB 7.9 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 62.1/216.1 MB 7.9 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 62.9/216.1 MB 7.8 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 64.0/216.1 MB 7.7 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 65.3/216.1 MB 7.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 66.3/216.1 MB 7.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 68.2/216.1 MB 7.6 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 69.2/216.1 MB 7.5 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 70.5/216.1 MB 7.5 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 71.8/216.1 MB 7.5 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 72.6/216.1 MB 7.4 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 74.4/216.1 MB 7.4 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 75.2/216.1 MB 7.3 MB/s eta 0:00:20\n",
      "   -------------- ------------------------- 77.1/216.1 MB 7.3 MB/s eta 0:00:19\n",
      "   -------------- ------------------------- 78.6/216.1 MB 7.3 MB/s eta 0:00:19\n",
      "   -------------- ------------------------- 80.2/216.1 MB 7.3 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 81.8/216.1 MB 7.3 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 83.1/216.1 MB 7.4 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 84.4/216.1 MB 7.3 MB/s eta 0:00:19\n",
      "   --------------- ------------------------ 86.0/216.1 MB 7.3 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 86.8/216.1 MB 7.3 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 87.8/216.1 MB 7.2 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 89.1/216.1 MB 7.1 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 90.7/216.1 MB 7.1 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 91.5/216.1 MB 7.1 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 93.3/216.1 MB 7.1 MB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 95.2/216.1 MB 7.1 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 96.2/216.1 MB 7.1 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 97.0/216.1 MB 7.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 98.3/216.1 MB 7.0 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 100.1/216.1 MB 7.1 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 100.7/216.1 MB 7.0 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 102.0/216.1 MB 7.0 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 103.5/216.1 MB 7.0 MB/s eta 0:00:17\n",
      "   ------------------- -------------------- 105.1/216.1 MB 7.0 MB/s eta 0:00:16\n",
      "   ------------------- -------------------- 107.0/216.1 MB 7.0 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 108.3/216.1 MB 7.0 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 109.6/216.1 MB 7.0 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 110.9/216.1 MB 7.0 MB/s eta 0:00:16\n",
      "   -------------------- ------------------- 112.5/216.1 MB 7.0 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 114.0/216.1 MB 7.0 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 115.3/216.1 MB 7.0 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 116.9/216.1 MB 7.0 MB/s eta 0:00:15\n",
      "   --------------------- ------------------ 118.2/216.1 MB 7.0 MB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 119.3/216.1 MB 6.9 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 120.3/216.1 MB 6.9 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 121.1/216.1 MB 6.9 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 121.9/216.1 MB 6.8 MB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 123.2/216.1 MB 6.8 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 124.5/216.1 MB 6.8 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 126.1/216.1 MB 6.8 MB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 127.9/216.1 MB 6.9 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 129.8/216.1 MB 6.9 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 131.3/216.1 MB 6.9 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 132.9/216.1 MB 6.9 MB/s eta 0:00:13\n",
      "   ------------------------ --------------- 134.5/216.1 MB 6.9 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 135.8/216.1 MB 6.9 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 137.1/216.1 MB 6.9 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 138.4/216.1 MB 6.9 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 139.7/216.1 MB 6.9 MB/s eta 0:00:12\n",
      "   -------------------------- ------------- 141.0/216.1 MB 6.9 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 141.8/216.1 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 142.9/216.1 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 144.4/216.1 MB 6.8 MB/s eta 0:00:11\n",
      "   -------------------------- ------------- 145.5/216.1 MB 6.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 146.8/216.1 MB 6.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 148.1/216.1 MB 6.8 MB/s eta 0:00:11\n",
      "   --------------------------- ------------ 149.2/216.1 MB 6.8 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 150.5/216.1 MB 6.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 151.5/216.1 MB 6.8 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 152.8/216.1 MB 6.7 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 154.1/216.1 MB 6.7 MB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 155.5/216.1 MB 6.7 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 156.5/216.1 MB 6.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 157.8/216.1 MB 6.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 159.1/216.1 MB 6.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 160.4/216.1 MB 6.7 MB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 161.2/216.1 MB 6.7 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 162.5/216.1 MB 6.7 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 163.8/216.1 MB 6.7 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 165.2/216.1 MB 6.7 MB/s eta 0:00:08\n",
      "   ------------------------------ --------- 166.7/216.1 MB 6.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 168.3/216.1 MB 6.7 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 170.1/216.1 MB 6.7 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 172.0/216.1 MB 6.7 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 173.8/216.1 MB 6.7 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 175.6/216.1 MB 6.7 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 176.9/216.1 MB 6.7 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 178.5/216.1 MB 6.7 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 180.1/216.1 MB 6.7 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 181.7/216.1 MB 6.7 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 183.0/216.1 MB 6.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 184.5/216.1 MB 6.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 186.1/216.1 MB 6.7 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 187.7/216.1 MB 6.8 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 188.7/216.1 MB 6.7 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 190.1/216.1 MB 6.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 191.1/216.1 MB 6.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 192.2/216.1 MB 6.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 193.2/216.1 MB 6.7 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 194.2/216.1 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 195.8/216.1 MB 6.7 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 197.4/216.1 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 199.0/216.1 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 200.3/216.1 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 201.9/216.1 MB 6.7 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 203.4/216.1 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 205.0/216.1 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 206.0/216.1 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 207.4/216.1 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 208.9/216.1 MB 6.6 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 210.2/216.1 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  211.6/216.1 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  213.1/216.1 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  214.4/216.1 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  216.0/216.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  216.0/216.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  216.0/216.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  216.0/216.1 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 216.1/216.1 MB 6.2 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.22.1-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.0/1.7 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 4.9 MB/s eta 0:00:00\n",
      "Installing collected packages: torch, torchvision, transformers\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.7.0\n",
      "    Uninstalling torch-2.7.0:\n",
      "      Successfully uninstalled torch-2.7.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.22.0\n",
      "    Uninstalling torchvision-0.22.0:\n",
      "      Successfully uninstalled torchvision-0.22.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.52.3\n",
      "    Uninstalling transformers-4.52.3:\n",
      "      Successfully uninstalled transformers-4.52.3\n",
      "Successfully installed torch-2.7.1 torchvision-0.22.1 transformers-4.52.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.7.0+cu118 requires torch==2.7.0+cu118, but you have torch 2.7.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Instala/actualiza y reinicia el kernel antes de pasar a la siguiente celda:\n",
    "%pip install --upgrade transformers datasets torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f245fc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52.4\n",
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n",
    "from transformers import PreTrainedModel, BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer\n",
    "print(\"Imports OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e59a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165fed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de etiquetas:\n",
      "labels\n",
      "0    200\n",
      "1    200\n",
      "2    200\n",
      "3    200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:/Users/carlo/OneDrive/Escritorio/Master/TFM/preprocessed.csv')\n",
    "# Eliminar filas sin etiqueta y convertir 'Label' a string\n",
    "df = df[df['Label'].notna()].copy()\n",
    "df['Label'] = df['Label'].astype(str)\n",
    "# Unificar nombre de la columna de texto si viene como 'Text'\n",
    "if 'Text' in df.columns:\n",
    "    df.rename(columns={'Text': 'text'}, inplace=True)\n",
    "\n",
    "# Mapear etiquetas a IDs y renombrar columna a 'labels'\n",
    "label_list = sorted(df['Label'].unique())\n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "df['labels'] = df['Label'].map(label2id)\n",
    "\n",
    "# Mostrar distribución de etiquetas\n",
    "print(\"Distribución de etiquetas:\")\n",
    "print(df['labels'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495e5d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de etiquetas (original):\n",
      "Label\n",
      "drug and alcohol     200\n",
      "early life           200\n",
      "personality          200\n",
      "trauma and stress    200\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspeccionar distribución de etiquetas antes de mapear IDs\n",
    "print(\"Distribución de etiquetas (original):\")\n",
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbcd567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. División train/test\n",
    "df_train, df_test = train_test_split(\n",
    "    df[['text', 'labels']],\n",
    "    test_size=0.2,\n",
    "    stratify=df['labels'],\n",
    "    random_state=42\n",
    ")\n",
    "train_ds = Dataset.from_pandas(df_train)\n",
    "test_ds = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62f42fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d0394cf1ca4c0c9d7aea7e9946c078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cc8a4ac5404b24a6e8e339ea7dffa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Tokenización con BERT\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "def tokenize(batch):\n",
    "    # Tokenizar y devolver los componentes necesarios para el modelo\n",
    "    return tokenizer(batch['text'], truncation=True, padding=True, max_length=256)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "test_ds = test_ds.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fffbb06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 4. Definir modelo de clasificación con BERT\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=len(label_list),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9274c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Data collator y métricas\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(p.label_ids, preds),\n",
    "        'f1_macro': f1_score(p.label_ids, preds, average='macro')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daa6fcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_5840\\134197435.py:11: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# 6. Configuración de entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    logging_steps=50\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb494c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\carlo\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='131' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [131/240 30:29 < 25:46, 0.07 it/s, Epoch 1.62/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.401900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.324600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. Entrenamiento y evaluación\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27182955",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FINAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc0c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = \"./results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ac892",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_FINAL:\n",
    "    # 1) Guarda el modelo final compacto en ./results (sobrescribe)\n",
    "    trainer.save_model(\"./results\")\n",
    "    tokenizer.save_pretrained(\"./results\")\n",
    "\n",
    "    # 2) Recarga desde ./results en variables nuevas\n",
    "    final_model     = AutoModelForSequenceClassification.from_pretrained(\"./results\")\n",
    "    final_tokenizer = AutoTokenizer.from_pretrained(\"./results\")\n",
    "\n",
    "    # 3) Define el deploy_dir *dentro* de DeteccionEM/api/model\n",
    "    BASE_DIR   = os.path.dirname(__file__)            # si tu script está en DeteccionEM/\n",
    "    deploy_dir = os.path.join(BASE_DIR, \"api\", \"model\")\n",
    "\n",
    "    # 4) Limpia antes para evitar bloqueos en Windows\n",
    "    if os.path.isdir(deploy_dir):\n",
    "        shutil.rmtree(deploy_dir)\n",
    "    os.makedirs(deploy_dir, exist_ok=True)\n",
    "\n",
    "    # 5) Guarda solo lo esencial\n",
    "    final_model.save_pretrained(deploy_dir)\n",
    "    final_tokenizer.save_pretrained(deploy_dir)\n",
    "    print(f\"Modelo final guardado en {deploy_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc6fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd C:\\…\\DeteccionEM\n",
    "# git add model1.ipynb 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc65775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# git add api/model\n",
    "# git commit -m \"Comentario del commit\"\n",
    "# git push origin main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
